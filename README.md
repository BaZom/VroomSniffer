# ğŸš— Caralyze - Car Scraper System

A modern, modular web scraping system designed to collect car listings from eBay Kleinanzeigen, detect new listings, and send notifications via Telegram. Built with Python, Playwright, and Streamlit.

## âœ¨ Key Features

- **ğŸ­ Modern Web Scraping**: Playwright-based engine handles JavaScript-heavy sites
- **ğŸ”„ Smart Deduplication**: Automatically detects and filters out duplicate listings
- **ğŸ“± Telegram Notifications**: Get instant alerts for new car listings with rich formatting
- **ğŸš€ Auto-Notifications**: Automatically send new listings as they're discovered
- **ğŸŒ Web Dashboard**: Interactive Streamlit interface with real-time monitoring
- **âš¡ CLI Interface**: Command-line tools for automation and scripting
- **ğŸ”§ Modular Architecture**: Clean separation of concerns for easy maintenance
- **ğŸ“Š Multiple Storage Options**: SQLite for development, PostgreSQL for production

## ğŸš€ Quick Start

### 1. Installation

**Clone the repository:**
```bash
git clone <your-repository-url>
cd car_scraper
```

**Create virtual environment:**
```bash
# Windows
python -m venv venv
.\venv\Scripts\Activate.ps1

# Linux/macOS  
python3 -m venv venv
source venv/bin/activate
```

**Install dependencies:**
```bash
pip install -r requirements.txt
playwright install
```

### 2. First Run

**Test the scraper:**
```bash
python cli/main.py run "https://www.kleinanzeigen.de/s-autos/bmw/k0c216"
```

**View results:**
```bash
python cli/main.py list
```

**Launch web interface:**
```bash
streamlit run ui/streamlit_app.py
```

## ğŸ“‹ Usage

### Command Line Interface

The CLI provides the primary interface for running the scraper and managing results:

```bash
# Run the scraper with a Kleinanzeigen search URL
python cli/main.py run "https://www.kleinanzeigen.de/s-autos/bmw/k0c216"

# Run with auto-notifications (sends new listings automatically)
python scraper/ebay_kleinanzeigen_engine.py --url "..." --notify --notify-count 3

# List the latest scraped listings
python cli/main.py list

# Search listings for specific keywords
python cli/main.py search "bmw x5"
python cli/main.py search "automatic"

# Send a listing via Telegram (use index from list command)
python cli/main.py send 3

# Send top 5 listings via Telegram
python cli/main.py send-top 5

# Send summary notification
python cli/main.py notify

# Show version information
python cli/main.py version

# Get help for any command
python cli/main.py --help
```

### Web Interface

Launch the interactive Streamlit dashboard for advanced filtering and monitoring:

```bash
streamlit run ui/streamlit_app.py
```

**Key Features:**
- **ğŸ”„ Auto-monitoring**: Enable automatic scraping every 5 minutes
- **ğŸ“² Auto-notifications**: Automatically send new listings to Telegram  
- **ğŸ›ï¸ Interactive controls**: Manual monitoring with one click
- **ğŸ“Š Real-time analytics**: Price trends and statistics
- **ğŸ” Advanced filtering**: Car make/model, price, year, transmission, mileage

**Auto-Monitoring Setup:**
1. Configure your search filters (car make, price range, etc.)
2. âœ… Check "ğŸ”„ Auto-run scraper every 5 minutes" 
3. âœ… Check "ğŸ“² Auto-send new listings" (optional)
4. The system will automatically check for new listings every 5 minutes
5. New listings are instantly sent to your Telegram

The web interface provides:
- Real-time listing monitoring
- **ğŸ”„ Auto-monitoring every 5 minutes** (new!)
- **ğŸ“² Auto-send new listings to Telegram** (new!)
- Advanced filtering options
- Price analysis and trends
- Visual data exploration
- Telegram integration

## Project Structure

```
car_scraper/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ cli/                     # Command-line interface
â”‚   â”œâ”€â”€ main.py             # Main CLI application
â”‚   â”œâ”€â”€ README.md           # CLI documentation
â”‚   â””â”€â”€ data/               # CLI-specific data storage
â”œâ”€â”€ ui/                     # Web interface
â”‚   â””â”€â”€ streamlit_app.py    # Streamlit web app
â”œâ”€â”€ scraper/                # Scraping engine
â”‚   â””â”€â”€ ebay_kleinanzeigen_engine.py
â”œâ”€â”€ services/               # Business logic layer
â”‚   â””â”€â”€ caralyze_service.py
â”œâ”€â”€ storage/                # Data persistence
â”‚   â”œâ”€â”€ db.py              # Database operations
â”‚   â””â”€â”€ listings/          # JSON data storage
â”œâ”€â”€ notifier/              # Notification system
â”‚   â””â”€â”€ telegram.py        # Telegram integration
â”œâ”€â”€ proxy/                 # Proxy management
â”‚   â””â”€â”€ manager.py
â”œâ”€â”€ utils/                 # Utilities
â”‚   â””â”€â”€ deduplication.py
â”œâ”€â”€ scheduler/             # Job scheduling
â”‚   â””â”€â”€ job.py
â”œâ”€â”€ config/                # Configuration
â”‚   â””â”€â”€ car_models.py
â”œâ”€â”€ logger/                # Logging
â”‚   â””â”€â”€ logging_config.py
â””â”€â”€ tests/                 # Test suite
    â”œâ”€â”€ test_end_to_end.py
    â””â”€â”€ test_service_layer.py
```

### Core Components
- `cli/` â†’ **Command-line interface** (organized in dedicated folder)
  - `cli/main.py` â†’ Main CLI application
  - `cli/data/` â†’ CLI-specific data storage
- `ui/` â†’ **Web interface** (Streamlit app)
- `scraper/` â†’ **Scraping engine** (Playwright logic)
- `services/` â†’ **Business logic** (service layer)
- `storage/` â†’ **Data persistence** (SQLite/PostgreSQL)
- `notifier/` â†’ **Notifications** (Telegram messaging)

### Supporting Components
- `proxy/manager.py` â†’ Proxy rotation
- `utils/deduplication.py` â†’ Detect repeated listings
- `scheduler/job.py` â†’ Time-based trigger
- `config/` â†’ Configuration settings
- `tests/` â†’ Test suite
- `logger/` â†’ Logging configuration

---

## Configuration

### Telegram Integration
Configure Telegram notifications for automatic car listing alerts:

**Setup Steps:**
1. Create a Telegram bot via @BotFather
2. Get your bot token and chat ID  
3. Configure environment variables in `.env`:
   ```env
   TELEGRAM_BOT_TOKEN=your_bot_token_here
   TELEGRAM_CHAT_ID=your_chat_id_here
   TELEGRAM_TEST_MODE=false  # Set to true for testing
   ```

**Auto-Notification Features:**
- **ğŸš€ Streamlit UI**: Toggle "Auto-send new listings" in sidebar for real-time notifications
- **âš¡ CLI Scraper**: Use `--notify` flag to auto-send listings after scraping
- **ğŸ“± Rich Formatting**: HTML messages with emojis, clickable links, and structured layout
- **ğŸ›¡ï¸ Rate Limiting**: Smart delays prevent spam and API limits
- **ğŸ”§ Test Mode**: Corporate-friendly mode for networks that block Telegram

### Proxy Support
Configure proxy rotation in `proxy/manager.py` for enhanced scraping reliability.

### Database Storage
- **SQLite**: Default lightweight option (configured in `storage/db.py`)
- **PostgreSQL**: Production-ready option for larger deployments

---

## Development

### Running Tests
```bash
python -m pytest tests/
```

### Project Architecture
The project follows a clean, modular architecture with separation of concerns:
- **CLI**: User interface and command handling
- **Scraper**: Web scraping logic using Playwright
- **Services**: Business logic and data processing
- **Storage**: Data persistence and management
- **UI**: Web-based dashboard and visualization
- **Utils**: Shared utilities and helpers

---

## Troubleshooting

- **Playwright issues**: Run `playwright install` to download browser binaries
- **Import errors**: Ensure you're in the virtual environment and all dependencies are installed
- **Scraping failures**: Check if the target website structure has changed
- **Telegram not working**: Verify bot token and chat ID in the notifier configuration

---

## Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/your-feature`
3. Make your changes and add tests
4. Run tests: `python -m pytest tests/`
5. Commit your changes: `git commit -am 'Add some feature'`
6. Push to the branch: `git push origin feature/your-feature`
7. Submit a pull request

---

## License

This project is licensed under the MIT License - see the LICENSE file for details.
